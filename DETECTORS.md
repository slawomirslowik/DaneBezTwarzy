# Detektory - Podsumowanie

## PrzeglÄ…d

Projekt **Dane Bez Twarzy** wykorzystuje **5 detektorÃ³w** dziaÅ‚ajÄ…cych rÃ³wnolegle do wykrywania danych osobowych. KaÅ¼dy detektor ma rÃ³Å¼ne podejÅ›cie, zaleÅ¼noÅ›ci i charakterystykÄ™ wydajnoÅ›ciowÄ….

---

## 1. **PlaceholderDetector** âœ…

### Opis
Wykrywa placeholdery w notacji kwadratowych nawiasÃ³w uÅ¼ywane w templatech i plikach treningowych (np. format NASK).

### Wykrywane wzorce
- `[name]`, `[surname]`, `[email]`, `[phone]`
- `[pesel]`, `[nip]`, `[regon]`, `[address]`, `[city]`
- `[birth-date]`, `[age]`, `[sex]`, `[job-title]`
- 30+ typÃ³w placeholderÃ³w

### Biblioteki
- `re` (regex - standardowa Python)
- `logging` (standardowa Python)
- **Brak zewnÄ™trznych zaleÅ¼noÅ›ci**

### Charakterystyka
- **PewnoÅ›Ä‡**: 1.0 (100% - najwyÅ¼sza)
- **SzybkoÅ›Ä‡**: âš¡âš¡âš¡âš¡âš¡ (bÅ‚yskawiczny)
- **Rozmiar**: ~5 KB
- **Status**: Zawsze aktywny

### Zastosowanie
Idealny dla dokumentÃ³w treningowych AI/ML, templatech emaili, plikÃ³w testowych.

---

## 2. **RegexDetector** âœ…

### Opis
Wykrywa dane osobowe przez deterministyczne wyraÅ¼enia regularne (regex).

### Wykrywane wzorce
- **PESEL**: `90010112345`
- **NIP**: `123-456-78-90`, `1234567890`
- **REGON**: `123456789`, `12345678901234`
- **Email**: `jan.kowalski@example.com`
- **Telefon**: `+48 123 456 789`, `123-456-789`
- **Konto bankowe**: `12 3456 7890 1234 5678 9012 3456`
- **Karty pÅ‚atnicze**: Visa, Mastercard, Amex
- **URL**, **IP Address**

### Biblioteki
- `re` (regex - standardowa Python)
- `logging` (standardowa Python)
- **Brak zewnÄ™trznych zaleÅ¼noÅ›ci**

### Charakterystyka
- **PewnoÅ›Ä‡**: 0.8-0.95 (wysoka)
- **SzybkoÅ›Ä‡**: âš¡âš¡âš¡âš¡âš¡ (bÅ‚yskawiczny)
- **Rozmiar**: ~10 KB
- **Status**: Zawsze aktywny

### Zastosowanie
Uniwersalny detektor dla strukturalnych danych (numery, formaty).

---

## 3. **PolishDetector** âœ…

### Opis
Specjalizowany detektor dla polskich wzorcÃ³w z uÅ¼yciem heurystyk i kontekstu.

### Wykrywane wzorce
- **Adresy**: `ul. Kwiatowa 15`, `al. Jerozolimskie 123/45`
- **Kody pocztowe**: `00-001`, `12-345`
- **Numery dokumentÃ³w**: dowÃ³d osobisty, prawo jazdy
- **Polskie imiona/nazwiska** (sÅ‚ownik + kontekst)
- **TytuÅ‚y**: Pan, Pani, Dr, Prof, Mgr, InÅ¼

### Biblioteki
- `logging` (standardowa Python)
- `typing` (standardowa Python)
- **Brak zewnÄ™trznych zaleÅ¼noÅ›ci**

### Charakterystyka
- **PewnoÅ›Ä‡**: 0.7-0.9 (dobra)
- **SzybkoÅ›Ä‡**: âš¡âš¡âš¡âš¡ (bardzo szybki)
- **Rozmiar**: ~15 KB
- **Status**: Aktywny automatycznie gdy `language="pl"`

### Zastosowanie
Dokumenty w jÄ™zyku polskim (urzÄ™dowe, CV, korespondencja).

---

## 4. **NLPDetector** âš ï¸

### Opis
Zaawansowany detektor uÅ¼ywajÄ…cy Named Entity Recognition (NER) przez spaCy do analizy kontekstowej.

### Wykrywane wzorce
- **Imiona i nazwiska**: Jan Kowalski, Anna Nowak
- **Organizacje**: Microsoft, Google Poland
- **Lokalizacje**: Warszawa, KrakÃ³w, ul. MarszaÅ‚kowska
- Rozpoznaje kontekst (nie tylko wzorce)

### Biblioteki
- **`spacy`** (gÅ‚Ã³wna biblioteka NLP) - ~10 MB
- **`pl_core_news_lg`** (model polski) - ~500 MB
- `logging` (standardowa Python)

### Charakterystyka
- **PewnoÅ›Ä‡**: 0.6-0.95 (bardzo dobra, zaleÅ¼y od kontekstu)
- **SzybkoÅ›Ä‡**: âš¡âš¡ (wolniejszy, ~100-500 ms/dokument)
- **Rozmiar**: ~500 MB (model)
- **Status**: Wymaga flagi `--use-nlp` lub `use_nlp=True`

### Zastosowanie
Dokumenty z tekstem naturalnym gdzie imiona/nazwiska nie majÄ… okreÅ›lonego formatu.

### Instalacja
```bash
pip install spacy
python -m spacy download pl_core_news_lg
```

---

## 5. **LLMDetector** ğŸ”¥

### Opis
Najbardziej zaawansowany detektor uÅ¼ywajÄ…cy modelu jÄ™zykowego PLLUM (12B parametrÃ³w) przez API.

### Wykrywane wzorce
- **Wszystko co wykrywajÄ… pozostaÅ‚e detektory**
- **Dane wraÅ¼liwe w kontekÅ›cie**: pseudonimy, przezwiska
- **Informacje ukryte**: â€Jej brat to..." (inferencja)
- **Niestandarowe formaty**: kreatywne zapisy danych
- Najlepsza precyzja dziÄ™ki rozumieniu jÄ™zyka naturalnego

### Biblioteki
- **`langchain-openai`** (integracja z LLM) - ~20 MB
- **ChatOpenAI** (klient API)
- `json`, `re`, `logging` (standardowe Python)

### Charakterystyka
- **PewnoÅ›Ä‡**: 0.85-0.98 (najwyÅ¼sza)
- **SzybkoÅ›Ä‡**: âš¡ (wolny, ~1-5s/dokument, zaleÅ¼y od API)
- **Rozmiar**: ~20 MB (biblioteka) + API zdalnie
- **Status**: Wymaga flagi `--use-llm` i klucza API
- **Chunking**: Automatyczny podziaÅ‚ duÅ¼ych plikÃ³w (3000 znakÃ³w/fragment)

### Zastosowanie
Krytyczne dokumenty wymagajÄ…ce maksymalnej precyzji (medyczne, prawne, HR).

### Instalacja
```bash
pip install langchain-openai
```

### UÅ¼ycie
```bash
dane-bez-twarzy anonymize input.txt -o output.txt \
  --use-llm \
  --llm-api-key "c670f40b37e0495c845c63b1e548d95a"
```

---

## PorÃ³wnanie

| Detektor | Biblioteki | Rozmiar | SzybkoÅ›Ä‡ | PewnoÅ›Ä‡ | Status |
|----------|-----------|---------|----------|---------|--------|
| **Placeholder** | Brak (tylko stdlib) | ~5 KB | âš¡âš¡âš¡âš¡âš¡ | 1.0 | Zawsze aktywny |
| **Regex** | Brak (tylko stdlib) | ~10 KB | âš¡âš¡âš¡âš¡âš¡ | 0.8-0.95 | Zawsze aktywny |
| **Polish** | Brak (tylko stdlib) | ~15 KB | âš¡âš¡âš¡âš¡ | 0.7-0.9 | Auto (gdy `lang=pl`) |
| **NLP** | **spaCy + model** | ~500 MB | âš¡âš¡ | 0.6-0.95 | `--use-nlp` |
| **LLM** | **langchain-openai** | ~20 MB | âš¡ (API) | 0.85-0.98 | `--use-llm` + API key |

---

## RÃ³Å¼nice kluczowe

### PodejÅ›cie do detekcji

1. **Placeholder, Regex, Polish**: Wzorce deterministyczne
   - Szybkie, przewidywalne
   - Nie wymagajÄ… ML/AI
   - DziaÅ‚ajÄ… offline

2. **NLP**: Machine Learning (spaCy)
   - Rozumie kontekst
   - Wymaga modelu (500 MB)
   - DziaÅ‚a offline po pobraniu modelu

3. **LLM**: Large Language Model (PLLUM)
   - Najinteligentniejszy (12B parametrÃ³w)
   - Rozumie jÄ™zyk naturalny i inferencjÄ™
   - Wymaga API (dziaÅ‚a online)

### ZaleÅ¼noÅ›ci

- **Bez zaleÅ¼noÅ›ci** (3 detektory): Placeholder, Regex, Polish
  - Idealne dla wersji LITE standalone EXE (~50 MB)
  
- **Z zaleÅ¼noÅ›ciami** (2 detektory): NLP, LLM
  - Wersja FULL z NLP: ~600 MB (standalone EXE)
  - LLM zawsze wymaga API (nie moÅ¼na spakowaÄ‡ modelu)

### Przypadki uÅ¼ycia

| Scenariusz | Rekomendowane detektory |
|-----------|------------------------|
| **Szybkie przetwarzanie** | Placeholder + Regex + Polish |
| **CV/dokumenty urzÄ™dowe** | + NLP |
| **Dokumenty medyczne/prawne** | + LLM |
| **Offline/standalone** | Placeholder + Regex + Polish (+ NLP jeÅ›li FULL) |
| **Maksymalna precyzja** | Wszystkie 5 detektorÃ³w |

---

## Strategia wyboru

```bash
# DomyÅ›lnie (szybkie, offline)
dane-bez-twarzy anonymize input.txt -o output.txt

# Z NLP (dokÅ‚adniejsze imiona/nazwiska)
dane-bez-twarzy anonymize input.txt -o output.txt --use-nlp

# Z LLM (maksymalna precyzja)
dane-bez-twarzy anonymize input.txt -o output.txt --use-llm --llm-api-key "klucz"

# ALL-IN (wszystkie detektory)
dane-bez-twarzy anonymize input.txt -o output.txt \
  --use-nlp --use-llm --llm-api-key "klucz"
```

---

## Architektura

Wszystkie detektory implementujÄ… interfejs:
```python
class Detector:
    def detect(self, text: str) -> List[Entity]:
        """Wykrywa encje w tekÅ›cie."""
        pass
```

Wyniki sÄ… Å‚Ä…czone i deduplikowane w `Anonymizer.detect()` z priorytetyzacjÄ…:
1. WyÅ¼sza pewnoÅ›Ä‡ (confidence)
2. DÅ‚uÅ¼szy tekst (gdy nakÅ‚adanie)
3. PÃ³Åºniejszy detektor (przy rÃ³wnoÅ›ci)

---

**Podsumowanie**: Projekt oferuje elastyczny system detektorÃ³w - od szybkich regex (bez zaleÅ¼noÅ›ci) po zaawansowany LLM (API), pozwalajÄ…c dostosowaÄ‡ trade-off miÄ™dzy szybkoÅ›ciÄ…, rozmiarem, kosztem a precyzjÄ….
